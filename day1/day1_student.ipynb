{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 1 Notebook\n",
    "This notebook covers an introduction to common python libraries (numpy, pandas, matplotlib) and the basics of Keras, culminating in building a linear regression model in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Python Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy\n",
    "A python library for handling arrays (matrices). Exercises adopted from this [lecture](https://compphysics.github.io/MachineLearningMSU/doc/pub/Introduction/html/Introduction.html). For full documentation see [Numpy website](https://numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start by importing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize an array (vector) of 10 elements. \n",
    "These elements are deterimined by random numbers drawn from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "x=np.random.normal(size=n)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also initialize an array with specific values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([1, 2, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Python starts numbering elements from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the first element of x\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the last element of x\n",
    "print(x[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also apply functions like log to an entire array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.log(np.array([4, 7, 8]))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* It's typically better to use the built in numpy functions because they're highly vectorized!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "Write a NumPy program to convert the values of Centigrade degrees into Fahrenheit degrees. Centigrade values are stored into a NumPy array.\n",
    "Sample Array [0, 12, 45.21 ,34, 99.91].\n",
    "\n",
    "Hint: C/5=(F-32)/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your solution here\n",
    "fvalues = [0, 12, 45.21, 34, 99.91]\n",
    "F = np.array(fvalues)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make matrices in numpy (and tensors of higher dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.log(np.array([ [4.0, 7.0, 8.0], [3.0, 10.0, 11.0], [4.0, 5.0, 7.0] ]))\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get information about the matrix and easily slice it (select specific values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the matrix size\n",
    "print(\"A size:\", A.shape)\n",
    "# make a new matrix B=log(A) print the first column, row-major order and elements start with 0\n",
    "B = np.log(np.array([ [4.0, 7.0, 8.0], [3.0, 10.0, 11.0], [4.0, 5.0, 7.0] ]))\n",
    "# print the first column, row-major order and elements start with 0\n",
    "print(\"first column of B:\", B[:,0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also functions to create matrices with certain values (0 or 1) or random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a matrix of dimension 10 x 10 and set all elements to zero\n",
    "A = np.zeros( (n, n) )\n",
    "print(\"A:\",A)\n",
    "# define a matrix of dimension 10 x 10 and set all elements to one\n",
    "B = np.ones( (n, n) )\n",
    "print(\"B\",B)\n",
    "# define a matrix of dimension 10 x 10 and set all elements to random numbers with x \\in [0, 1]\n",
    "C = np.random.rand(n, n)\n",
    "print(\"C\",C) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "Define two 2x2 matrices, one randomly initialized and one defined, and multiply them. Is the answer what you expect?\n",
    "\n",
    "Hint: check the documentation for multiply and dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your solultion here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is MUCH more functionality in numpy, but it can be easiest to learn by looking at the documentation as you try exercises. Additional Numpy exercises can be found [here](https://www.w3resource.com/python-exercises/numpy/index.php)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas\n",
    "A python library for data structures and analysis tools. Exercises adopted from this [lecture](https://compphysics.github.io/MachineLearningMSU/doc/pub/Introduction/html/Introduction.html). For full documentation see [Pandas website](https://pandas.pydata.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas let's us make Dataframes (tensors) and Series (vectors). Let's initialize a matrix of LoTR characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'First Name': [\"Frodo\", \"Bilbo\", \"Aragorn II\", \"Samwise\"],\n",
    "        'Last Name': [\"Baggins\", \"Baggins\",\"Elessar\",\"Gamgee\"],\n",
    "        'Place of birth': [\"Shire\", \"Shire\", \"Eriador\", \"Shire\"],\n",
    "        'Date of Birth T.A.': [2968, 2890, 2931, 2980]\n",
    "        }\n",
    "data_pandas = pd.DataFrame(data)\n",
    "data_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily change the Dataframe to be indexed by a different value, let's change it to character first name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pandas_name = pd.DataFrame(data,index=['Frodo','Bilbo','Aragorn','Sam'])\n",
    "data_pandas_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can find info about a specific index value (row). Let's get info about Aragorn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pandas_name.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create data frames of purely numerical data (here our index could be samples and the columns could be different variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "# setting up a 10 x 5 matrix\n",
    "rows = 10\n",
    "cols = 5\n",
    "a = np.random.randn(rows,cols)\n",
    "df = pd.DataFrame(a)\n",
    "df.columns = ['vara', 'varb', 'varc', 'vard', 'vare']\n",
    "df.index = np.arange(10)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And get basic info about the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean:\", df.mean())\n",
    "print(\"standard deviation:\", df.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Select the second column of our dataframe and display the mean. Select the last column of our dataframe and describe it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is an extremely powerful library for reading (as we'll see in our linear regression model) and manipulating all kinds of data. Additional Pandas exercises can be found [here](https://www.w3resource.com/pandas/index.php)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Matplotlib](https://matplotlib.org/) is a library for easily creating and customizing plots in Python. There are other similar/useful libraries like [seaborn](https://seaborn.pydata.org/) and [plotly](https://plotly.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily create plots directly from numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#generate data points of the sine function\n",
    "x = np.linspace(-10,10,100)\n",
    "y = np.sin(x)\n",
    "## plot it \n",
    "plt.plot(x,y,marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also easily create plots from pandas dataframes. In fact, there is a pandas wrapper for matplotlib that let's you call plotting directly from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a randomized data frame\n",
    "df2 = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot it as a bar graph\n",
    "df2.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** create a green histogram of the third column of our dataframe df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplot offers MANY different kinds of plots. Additional exercises can be found [here](https://www.w3resource.com/graphics/matplotlib/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Keras and Linear Regression\n",
    "[Keras](https://keras.io/) is an intuitive machine learning API built on top of the TensorFlow library. In this exercise we will build a linear regression model using the [Auto MPG] Dataset. This exercise is adopted from the [Keras Tutorial](https://www.tensorflow.org/tutorials/keras/regression). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras and seaborn (for plotting)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Auto MPG Dataset is taken from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/) and has the data to build a model to predict fuel efficiency of late 1970s and early 1980s automobiles. It includes information like cylinders, displacement, horsepower, and weight. \n",
    "\n",
    "Let's read it in as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "raw_dataset = pd.read_csv(url, names=column_names,\n",
    "                          na_values='?', comment='\\t',\n",
    "                          sep=' ', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy for manipulation\n",
    "dataset = raw_dataset.copy()\n",
    "# print the last values of the dataframe\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always important to clean the data before building a model. Let's check if there are any missing values in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 NaN values in the horsepower column. Because we have ~400 values, we can just drop these rows to keep this exercise simple (note, this is often not best practice for dealing with missing data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with nan values\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The origin column actually describes the country of origin of the automobile with the following mapping: 1=USA, 2=Europe, 3=Japan. Let's turn this into a one-hot encoded column so we can use it in our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the mapping and replace the origin values\n",
    "dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
    "#use get_dummies (another great pandas function) to create one-hot columns\n",
    "dataset = pd.get_dummies(dataset, prefix='', prefix_sep='')\n",
    "#get the first rows of df\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** before building our model what else should we do to our dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** while there are many things we could look at, we should definitely separate a test and train split. Here, because we're not iterating over model designs we'll skip the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the joint distrubtion of some column pairs from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_dataset[['MPG', 'Cylinders', 'Displacement', 'Weight']], diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `describe` to get more info about the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** what kinds of patterns do you see here that you expect will be relevant to the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we're building a supervised model to predict the MPG of each car, we need to create a separate vector of the training and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('MPG')\n",
    "test_labels = test_features.pop('MPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often important to normalize the variables before building a model so that one variable doesn't wash out the information from others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean and std of each column\n",
    "train_dataset.describe().transpose()[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras has a built in functionality to build normalization preprocessing into your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "#create the normalization layer\n",
    "normalizer = preprocessing.Normalization()\n",
    "# get the specific values for our data\n",
    "normalizer.adapt(np.array(train_features))\n",
    "# we can look at these values and compare them to what we saw above\n",
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple single-variable regression to predict MPG from only Horsepower. First, we have to define the model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get just the horsepower\n",
    "horsepower = np.array(train_features['Horsepower'])\n",
    "\n",
    "## normalize it \n",
    "horsepower_normalizer = preprocessing.Normalization()\n",
    "horsepower=horsepower_normalizer(horsepower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the sequential layer (using a standard dense layer (matrix multiplication) of order 1)\n",
    "horsepower_model = tf.keras.Sequential([\n",
    "    keras.Input(shape=(1,)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "horsepower_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the model gives us the expected dimensionality (though the values will be terrible since we haven't trained yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model on first 10 rows\n",
    "horsepower_model.predict(horsepower[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model using the `Model.compile()` method. We must specify the loss (we'll use mean absolute error) and the optimizer (we'll use Adam, a type of gradient descent algorithm that we'll learn more about tomorrow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure training \n",
    "horsepower_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#run the training! \n",
    "history = horsepower_model.fit(\n",
    "    train_features['Horsepower'], train_labels,\n",
    "    epochs=100,\n",
    "    # suppress logging\n",
    "    verbose=0,\n",
    "    # Calculate validation results on 20% of the training data\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the model's training process using the stats stored in the `history` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training history\n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.ylim([0, 10])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [MPG]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check performance on test set\n",
    "\n",
    "score = horsepower_model.evaluate(\n",
    "    horsepower_normalizer(test_features['Horsepower']),\n",
    "    test_labels, verbose=0)\n",
    "\n",
    "print('Test Loss:', score[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** repeat liner regression training with multiple variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
